# -*- coding: utf-8 -*-
"""Nanny_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VrK5n1YkFGVzOziYUShi681M15HdFC4U
"""

!pip install nannyml

import nannyml as nml
from IPython.display import display

# Load synthetic data
reference, analysis, analysis_target = nml.load_synthetic_binary_classification_dataset()
display(reference.head())
display(analysis.head())

# Choose a chunker or set a chunk size
chunk_size = 5000

# initialize, specify required data columns, fit estimator and estimate
estimator = nml.CBPE(
    y_pred_proba='y_pred_proba',
    y_pred='y_pred',
    y_true='work_home_actual',
    metrics=['roc_auc'],
    chunk_size=chunk_size,
    problem_type='classification_binary',
)
estimator = estimator.fit(reference)
estimated_performance = estimator.estimate(analysis)


# CBPE provides unbiased estimation of performance of the monitored model based on the monitored model’s outputs only (i.e. without access to targets).


#y_pred_proba (ModelOutputsType) – Name(s) of the column(s) containing your model output.
#y_pred (str) – The name of the column containing your model predictions.
#y_true (str) – The name of the column containing target values (that are provided in reference data during fitting).
#metrics – A list of metrics to calculate.
#chunk_size – Splits the data into chunks containing chunks_size observations
#fit function = Fits a Metric on reference data
#estimate function = The data to estimate performance metrics for. Requires presence of either the predicted labels or prediction scores/probabilities (depending on the metric to be calculated).

# Show results
figure = estimated_performance.plot(kind='performance', metric='roc_auc', plot_reference=True)
figure.show()

#Here alerts are shown in the analysis period where the performance has went down.

# Define feature columns
feature_column_names = [
    col for col in reference.columns if col not in [
        'timestamp', 'period', 'work_home_actual', 'identifier'
    ]]

# Let's initialize the object that will perform the Univariate Drift calculations
univariate_calculator = nml.UnivariateDriftCalculator(
    column_names=feature_column_names,
    chunk_size=chunk_size,
    continuous_methods=['kolmogorov_smirnov', 'jensen_shannon'],
    categorical_methods=['chi2'],
)
univariate_calculator = univariate_calculator.fit(reference)
univariate_results = univariate_calculator.calculate(analysis)


#The UnivariateDriftCalculator class implements the functionality needed for univariate drift detection.
#Next, the fit() method needs to be called on the reference data, which provides the baseline that the analysis data will be compared with. 
#Then the calculate() method will calculate the drift results on the data provided to it.

# Plot drift results for all continuous columns
for column_name in univariate_calculator.continuous_column_names:
    figure = univariate_results.plot(
        kind='drift',
        method='jensen_shannon',
        column_name=column_name,
        plot_reference=True
    )
    figure.show()

# Plot drift results for all categorical columns
for column_name in univariate_calculator.categorical_column_names:
    figure = univariate_results.plot(
        kind='drift',
        method='chi2',
        column_name=column_name,
        plot_reference=True
    )
    figure.show()

# Let's initialize the object that will perform Data Reconstruction with PCA
rcerror_calculator = nml.DataReconstructionDriftCalculator(
    column_names=feature_column_names,
    chunk_size=chunk_size
).fit(reference_data=reference)
# let's see Reconstruction error statistics for all available data
rcerror_results = rcerror_calculator.calculate(analysis)
figure = rcerror_results.plot(kind='drift', plot_reference=True)
figure.show()